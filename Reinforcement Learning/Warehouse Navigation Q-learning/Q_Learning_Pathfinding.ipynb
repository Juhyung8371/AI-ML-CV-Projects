{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Pathfinding using Q-learning method\n",
        "\n",
        "In this scenario, I will use the q-learning method to teach warehouse robots to find the best path between a location in the warehouse and the drop-off location. I will also discuss congestion problems that may arise from every robot taking the same optimal path.\n",
        "This project is inspired by [this tutorial](https://youtu.be/iKdlKYG78j4).\n"
      ],
      "metadata": {
        "id": "HQcWOoEZW4O8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## What is Q-Learning?\n",
        "- Q-learning is a type of reinforcement learning method. It involves states(map), actions (input), and rewards (output).\n",
        "- Q-learning does not involve probabilistic models. Instead, it creates the optimal policy via trial and error.\n",
        "\n",
        "## Q-value\n",
        "- The Q-value indicates the quality of the action in a given state.\n",
        "- A higher Q-value means more reward.\n",
        "- Every combination of state and action has a Q-value associated with it. This information is stored in a Q-table (policy).\n",
        "- The states and the actions must be finite.\n",
        "\n",
        "## Temporal Difference\n",
        "<img src='https://github.com/Juhyung8371/AI-ML-CV-Projects/blob/main/Artificial%20Intelligence/Reinforcement%20Learning/Q-Learning/Warehouse%20Navigation/Temporal%20Difference.png?raw=true' width=600>\n",
        "\n",
        "[image source](https://youtu.be/__t2XRxXGxI)\n",
        "\n",
        "- The temporal difference is a method of considering current rewards in evaluating past actions.\n",
        "\n",
        "<img src='https://github.com/Juhyung8371/AI-ML-CV-Projects/blob/main/Artificial%20Intelligence/Reinforcement%20Learning/Q-Learning/Warehouse%20Navigation/Bellman%20Equation.png?raw=true' width=600>\n",
        "\n",
        "[image source](https://youtu.be/__t2XRxXGxI)\n",
        "\n",
        "- Then, we can use the Bellman Equation to update the Q-value"
      ],
      "metadata": {
        "id": "tCKxVT4NXxgG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define the environment\n",
        "\n",
        "States: 11 x 11 grid\n",
        "\n",
        "Actions: up, right, down, and left\n",
        "\n",
        "Each cell in the grid is either a wall, a road, or the goal. The environmental feedback is the following:\n",
        "\n",
        "1. a penalty for traveling through the wall\n",
        "2. a penalty for not taking the best path\n",
        "3. a reward for reaching the goal"
      ],
      "metadata": {
        "id": "D1Crjp69NtoN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1026,
      "metadata": {
        "id": "KQoMn3jW3Ho4"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#define the shape of the environment (i.e., its states).\n",
        "#11x11 grid\n",
        "environment_rows = 11\n",
        "environment_columns = 11\n",
        "\n",
        "#Create a 3D numpy array to hold the current Q-values for each\n",
        "#state and action pair: Q(s, a)\n",
        "q_values = np.zeros((environment_rows, environment_columns, 4))"
      ],
      "metadata": {
        "id": "979B-3HP3UVO"
      },
      "execution_count": 1027,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#define actions\n",
        "actions = ['up', 'right', 'down', 'left']"
      ],
      "metadata": {
        "id": "_bwVvHsW3teU"
      },
      "execution_count": 1028,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# default rewards for each block type\n",
        "\n",
        "# a penalty for traveling through the wall\n",
        "wall = -100.\n",
        "# a penalty for not taking the best path\n",
        "road = -1.\n",
        "# a reward for reaching the goal\n",
        "goal = 50."
      ],
      "metadata": {
        "id": "bji7_KS67vvV"
      },
      "execution_count": 1029,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a 2D numpy array to hold the rewards for each state.\n",
        "rewards = np.full((environment_rows, environment_columns), wall)\n",
        "\n",
        "rewards[0, 5] = goal #set the reward for the goal\n",
        "\n",
        "#define aisle locations for rows 1 through 9\n",
        "aisles = {} #store locations in a dictionary\n",
        "aisles[1] = [i for i in range(1, 10)]\n",
        "aisles[2] = [1, 7, 9]\n",
        "aisles[3] = [i for i in range(1, 8)]\n",
        "aisles[3].append(9)\n",
        "aisles[4] = [3, 7]\n",
        "aisles[5] = [i for i in range(11)]\n",
        "aisles[6] = [5]\n",
        "aisles[7] = [i for i in range(1, 10)]\n",
        "aisles[8] = [3, 7]\n",
        "aisles[9] = [i for i in range(11)]\n",
        "\n",
        "#set the rewards for all aisle locations\n",
        "for row_index in range(1, environment_columns-1):\n",
        "  for column_index in aisles[row_index]:\n",
        "    rewards[row_index, column_index] = road\n",
        "\n",
        "#print rewards matrix\n",
        "print(rewards)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Fgq3r8F3xpE",
        "outputId": "677de369-88d5-41dc-f2bb-b985c2d8d33c"
      },
      "execution_count": 1030,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-100. -100. -100. -100. -100.   50. -100. -100. -100. -100. -100.]\n",
            " [-100.   -1.   -1.   -1.   -1.   -1.   -1.   -1.   -1.   -1. -100.]\n",
            " [-100.   -1. -100. -100. -100. -100. -100.   -1. -100.   -1. -100.]\n",
            " [-100.   -1.   -1.   -1.   -1.   -1.   -1.   -1. -100.   -1. -100.]\n",
            " [-100. -100. -100.   -1. -100. -100. -100.   -1. -100. -100. -100.]\n",
            " [  -1.   -1.   -1.   -1.   -1.   -1.   -1.   -1.   -1.   -1.   -1.]\n",
            " [-100. -100. -100. -100. -100.   -1. -100. -100. -100. -100. -100.]\n",
            " [-100.   -1.   -1.   -1.   -1.   -1.   -1.   -1.   -1.   -1. -100.]\n",
            " [-100. -100. -100.   -1. -100. -100. -100.   -1. -100. -100. -100.]\n",
            " [  -1.   -1.   -1.   -1.   -1.   -1.   -1.   -1.   -1.   -1.   -1.]\n",
            " [-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define utilty functions"
      ],
      "metadata": {
        "id": "_yZhpl1h4GYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#define a function that determines if the specified location is a terminal state\n",
        "def is_terminal_state(current_row_index, current_column_index):\n",
        "  block = rewards[current_row_index, current_column_index]\n",
        "  return block == wall or block == goal"
      ],
      "metadata": {
        "id": "11gxuuhQ4Lcd"
      },
      "execution_count": 1031,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#define a function that will choose a random, non-terminal starting location\n",
        "def get_starting_location():\n",
        "  current_row_index = np.random.randint(environment_rows)\n",
        "  current_column_index = np.random.randint(environment_columns)\n",
        "\n",
        "  #continue choosing random row and column indexes until a non-terminal state is identified\n",
        "  while is_terminal_state(current_row_index, current_column_index):\n",
        "    current_row_index = np.random.randint(environment_rows)\n",
        "    current_column_index = np.random.randint(environment_columns)\n",
        "\n",
        "  return current_row_index, current_column_index"
      ],
      "metadata": {
        "id": "k-BMRF9p4LXl"
      },
      "execution_count": 1032,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#define an epsilon greedy algorithm that will choose which action to take next\n",
        "def get_next_action_index(current_row_index, current_column_index, epsilon):\n",
        "  # choosing a random action can introduce variance\n",
        "  # which can help the agent escape a local optima\n",
        "  if np.random.random() < epsilon:\n",
        "    return np.argmax(q_values[current_row_index, current_column_index])\n",
        "  else:\n",
        "    return np.random.randint(4)"
      ],
      "metadata": {
        "id": "KIoa5kgq4O3U"
      },
      "execution_count": 1033,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#define a function that will get the next location based on the chosen action\n",
        "#a.k.a. collision testing\n",
        "def get_next_location(current_row_index, current_column_index, action_index):\n",
        "  new_row_index = current_row_index\n",
        "  new_column_index = current_column_index\n",
        "  if actions[action_index] == 'up' and current_row_index > 0:\n",
        "    new_row_index -= 1\n",
        "  elif actions[action_index] == 'right' and current_column_index < environment_columns - 1:\n",
        "    new_column_index += 1\n",
        "  elif actions[action_index] == 'down' and current_row_index < environment_rows - 1:\n",
        "    new_row_index += 1\n",
        "  elif actions[action_index] == 'left' and current_column_index > 0:\n",
        "    new_column_index -= 1\n",
        "  return new_row_index, new_column_index"
      ],
      "metadata": {
        "id": "cgPMw14y4Qfa"
      },
      "execution_count": 1034,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function that will get the shortest path between\n",
        "# any 'legal' starting location and the item packaging location.\n",
        "def get_shortest_path(start_row_index, start_column_index):\n",
        "  #exit immediately if this is an invalid starting location\n",
        "  if is_terminal_state(start_row_index, start_column_index):\n",
        "    return []\n",
        "  else: #if this is a 'legal' starting location\n",
        "    current_row_index, current_column_index = start_row_index, start_column_index\n",
        "    shortest_path = []\n",
        "    shortest_path.append([current_row_index, current_column_index])\n",
        "    #continue moving along the path until we reach the goal (i.e., the item packaging location)\n",
        "    while not is_terminal_state(current_row_index, current_column_index):\n",
        "      #get the best action to take\n",
        "      action_index = get_next_action_index(current_row_index, current_column_index, 1.)\n",
        "      #move to the next location on the path, and add the new location to the list\n",
        "      current_row_index, current_column_index = get_next_location(current_row_index, current_column_index, action_index)\n",
        "      shortest_path.append([current_row_index, current_column_index])\n",
        "    return shortest_path"
      ],
      "metadata": {
        "id": "SNG_XhPH4Jo_"
      },
      "execution_count": 1035,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "NSb-2AEg5Sfb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# learning_rate: the rate at which the AI agent should learn\n",
        "# discount_factor: higher value means the future rewards means more than current rewards\n",
        "# epsilon: the percentage of time when we should take the best action (instead of a random action)\n",
        "def train(learning_rate=0.9, discount_factor=0.9, epsilon=0.7, reset_q=True):\n",
        "\n",
        "  if reset_q:\n",
        "    global q_values\n",
        "    q_values = np.zeros((environment_rows, environment_columns, 4))\n",
        "\n",
        "  #run through 10000 training episodes\n",
        "  for episode in range(10000):\n",
        "    #get the starting location for this episode\n",
        "    row_index, column_index = get_starting_location()\n",
        "\n",
        "    #continue taking actions (i.e., moving) until we reach a terminal state\n",
        "    #(i.e., until we reach the item packaging area or crash into an item storage location)\n",
        "    while not is_terminal_state(row_index, column_index):\n",
        "      #choose which action to take (i.e., where to move next)\n",
        "      action_index = get_next_action_index(row_index, column_index, epsilon)\n",
        "\n",
        "      #perform the chosen action, and transition to the next state (i.e., move to the next location)\n",
        "      old_row_index, old_column_index = row_index, column_index #store the old row and column indexes\n",
        "      row_index, column_index = get_next_location(row_index, column_index, action_index)\n",
        "\n",
        "      #receive the reward for moving to the new state, and calculate the temporal difference\n",
        "      reward = rewards[row_index, column_index]\n",
        "      old_q_value = q_values[old_row_index, old_column_index, action_index]\n",
        "      temporal_difference = reward + (discount_factor * np.max(q_values[row_index, column_index])) - old_q_value\n",
        "\n",
        "      #update the Q-value for the previous state and action pair using the Bellman Equation\n",
        "      new_q_value = old_q_value + (learning_rate * temporal_difference)\n",
        "      q_values[old_row_index, old_column_index, action_index] = new_q_value\n",
        "\n",
        "  print('Training complete!')"
      ],
      "metadata": {
        "id": "7yGKp6Ti5R19"
      },
      "execution_count": 1036,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UWTUphNML4Ro",
        "outputId": "99b28f9f-e291-48bf-9212-29146080c997"
      },
      "execution_count": 1037,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Result"
      ],
      "metadata": {
        "id": "eIphuIf9NnTq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(get_shortest_path(3, 9)) #starting at row 3, column 9\n",
        "print(get_shortest_path(5, 0)) #starting at row 5, column 0\n",
        "print(get_shortest_path(9, 5)) #starting at row 9, column 5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l8mlrTPz5WPQ",
        "outputId": "049c76a3-594a-41cc-ca8f-a3d4f647ae57"
      },
      "execution_count": 1038,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[3, 9], [2, 9], [1, 9], [1, 8], [1, 7], [1, 6], [1, 5], [0, 5]]\n",
            "[[5, 0], [5, 1], [5, 2], [5, 3], [4, 3], [3, 3], [3, 4], [3, 5], [3, 6], [3, 7], [2, 7], [1, 7], [1, 6], [1, 5], [0, 5]]\n",
            "[[9, 5], [9, 4], [9, 3], [8, 3], [7, 3], [7, 4], [7, 5], [6, 5], [5, 5], [5, 6], [5, 7], [4, 7], [3, 7], [2, 7], [1, 7], [1, 6], [1, 5], [0, 5]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# visualize the map and the path for easier interpretation of the path\n",
        "def make_map(rewardmap, path):\n",
        "  upsize_factor = 30\n",
        "  rows, columns = rewardmap.shape\n",
        "  map_img = np.full((environment_rows*upsize_factor, environment_columns*upsize_factor, 3), 255, dtype=np.uint8)\n",
        "\n",
        "  for r in range(0, rows):\n",
        "    for c in range(0, columns):\n",
        "      current_block = rewardmap[r][c]\n",
        "\n",
        "      wid = upsize_factor\n",
        "      hei = upsize_factor\n",
        "      color = -1\n",
        "      draw_r = r * upsize_factor\n",
        "      draw_c = c * upsize_factor\n",
        "\n",
        "      if current_block == wall:\n",
        "        color = 0\n",
        "      elif current_block == goal:\n",
        "        color = 150\n",
        "      else:\n",
        "        color = 255\n",
        "\n",
        "      if color != -1:\n",
        "        for y in range(0, upsize_factor):\n",
        "          for x in range(0, upsize_factor):\n",
        "            map_img[draw_r+y][draw_c+x] = [color, color, color]\n",
        "\n",
        "      index_remove = -1\n",
        "\n",
        "      for i, coord in enumerate(path):\n",
        "        if coord == [r, c]:\n",
        "          index_remove = i\n",
        "          move = int(float(upsize_factor) / 4.)\n",
        "          half = int(float(upsize_factor) / 2.)\n",
        "          for y in range(0, half):\n",
        "            for x in range(0, half):\n",
        "              map_img[draw_r+y+move][draw_c+x+move] = [255, 0, 0]\n",
        "\n",
        "      if index_remove != -1:\n",
        "        del path[index_remove]\n",
        "\n",
        "  return map_img"
      ],
      "metadata": {
        "id": "eHuIOfkX6A8n"
      },
      "execution_count": 1039,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cv2_imshow(make_map(rewards, get_shortest_path(9, 4)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "id": "j6tAkjcI6-Ej",
        "outputId": "88b2e07c-b17d-4c4e-be9f-1bbb16beb533"
      },
      "execution_count": 1040,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=330x330>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUoAAAFKCAIAAAD0S4FSAAAEfklEQVR4nO3dQYrbQBBAUSvksvGBPMd1LhBwBCpJ/f3eehDGzKcWcndtDxb3er2Gnvx8PoeezDl+Xf0BgCnyhix5Q5a8IUvekCVvyPp99QdgxPP55///+PX6mfskXMj0hix5Q5a8IUvekCVvyJI3ZMkbsuQNWfKGLHlDlrwhS96QJW/IkjdkORDa5IwnD9MbwuQNWfKGLHlDlrwhS96QJW/I2uYe/X6/5x4OGds2laHpDVnyhix5Q5a8IUvekCVvyHIgtGnXq5ZdbzBXfPLXMr0hS96QJW/IkjdkyRuy5A1Z8oYseUOWvCFL3pAlb8iSN2TJG7LkDVluSoWLuSkV2E3ekCVvyJI3ZMkbsuQNWfKGrCUvQp57T8g55n4TMfe/seLvOExvyJI3ZMkbsuQNWfKGLHlD1pIvxkiyIfRwpjdkyRuy5A1Z8oYseUOWvCFL3pAlb8iSN2TJG7LkDVnyhix5Q5a8IcuBUO7CGc/Dmd6QJW/IkjdkyRuy5A1Z8oYseUPWku+9V9zVCOczvSFL3pAlb8iSN2TJG7LkDVlLvhgjyYbQw5nekCVvyJI3ZMkbsuQNWfKGLHlDlrwhS96QJW/IkjdkyRuy5A1Z8oYsB0K5C2c8D2d6Q5a8IUvekCVvyJI3ZMkbsuQNWXvunv0Cc7tHt13X/Nb5ns9hekOWvCFL3pAlb8iSN2TJG7IcCOUubAg9nOkNWfKGLHlDlrwhS96QJW/IkjdkyRuy5A1Z8oYseUOWvCFL3pAlb8hyIJS7cMbzcKY3ZMkbsuQNWfKGLHlDlrwhS96Qtc3tagSuZXpDlrwhS96QJW/IkjdkyRuyHAhtmtu2ueKTv5bpDVnyhix5Q5a8IUvekCVvyJI3ZMkbsuQNWfKGLHlDlrwhS96QJW/IclMqZJnekCVvyJI3ZMkbsuQNWfKGLHlD1p67Z7mluV8ubLuuJuZ+TG/IkjdkyRuy5A1Z8oYseUOWDaFNtm3yML0hTN6QJW/IkjdkyRuy5A1Z8oYseUOWvCFL3pAlb8iSN2TJG7LkDVkOhDY548nD9IYweUOWvCFL3pAlb8iSN2TJG7IGV0DOba6EkrlNrKY3ZMkbsuQNWfKGLHlDlrwhy4HQz+a2ba74ZBZiekOWvCFL3pAlb8iSN2TJG7LkDVnyhix5Q5a8IUvekCVvyJI3ZMkbstyUChdzUyqwm7whS96QJW/IkjdkyRuy5A1Zg++9VzT3rn7u3eaKfM/nML0hS96QJW/IkjdkyRuy5A1ZNoR+ZtsmizK9IUvekCVvyJI3ZMkbsuQNWfKGLHlDlrwhS96QJW/IkjdkyRuy5A1ZDoR+5ownizK9IUvekCVvyJI3ZMkbsuQNWfKGrG1uVyNwLdMbsuQNWfKGLHlDlrwhS96Q5UDoZ3MbQu0eZZTpDVnyhix5Q5a8IUvekCVvyJI3ZMkbsuQNWfKGLHlDlrwhS96QJW/IclMqZJnekCVvyJI3ZMkbsuQNWfKGLHkDAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMA//AX2WGQbiJ7pmQAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cv2_imshow(make_map(rewards, get_shortest_path(5, 0)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "id": "5zO1kyfRXmYh",
        "outputId": "4924e720-5f06-4236-a15b-f17d045110ea"
      },
      "execution_count": 1041,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=330x330>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUoAAAFKCAIAAAD0S4FSAAAEYElEQVR4nO3dUWrjMBRA0XroZscLcpeb2UAgY+izo5tzvoswoZf3YUvavljccRxDK+/7PrQy1/hz9wMAU+QNWfKGLHlDlrwhS96Q9X33AzBi3//+/x8fx8/ck3Aj0xuy5A1Z8oYseUOWvCFL3pAlb8iSN2TJG7LkDVnyhix5Q5a8IUvekGVDaJM9nnyZ3hAmb8iSN2TJG7LkDVnyhix5Q9Y2t/Tj8ZhbHDK2bSpD0xuy5A1Z8oYseUOWvCFL3pBlQ2jTqVctp95grrjyxzK9IUvekCVvyJI3ZMkbsuQNWfKGLHlDlrwhS96QJW/IkjdkyRuy5A1ZTkqFmzkpFThN3pAlb8iSN2TJG7LkDVnyhqwlD0Kee0/INea+iZj731jxOw7TG7LkDVnyhix5Q5a8IUvekLXkizGS3BD660xvyJI3ZMkbsuQNWfKGLHlDlrwhS96QJW/IkjdkyRuy5A1Z8oYseUOWDaG8C3s8f53pDVnyhix5Q5a8IUvekCVvyJI3ZC353nvFuxrheqY3ZMkbsuQNWfKGLHlDlrwha8kXYxebu7nSytes/LFMb8iSN2TJG7LkDVnyhix5Q5a8IUvekCVvyJI3ZMkbsuQNWfKGLHlDlg2hr83tPbTyNSt/LNMbsuQNWfKGLHlDlrwhS96QJW/IOnP27AeYu3t0O3XMb53f+RqmN2TJG7LkDVnyhix5Q5a8IcuG0NfcXMmiTG/IkjdkyRuy5A1Z8oYseUOWvCFL3pAlb8iSN2TJG7LkDVnyhix5Q5YNoa/Z48miTG/IkjdkyRuy5A1Z8oYseUOWvCFrm7urEbiX6Q1Z8oYseUOWvCFL3pAlb8h6viF07k5MK8NlTG/IkjdkyRuy5A1Z8oYseUOWvCFL3pAlb8iSN2TJG7LkDVnyhix5Q5aTUiHL9IYseUOWvCFL3pAlb8iSN2TJG7LOnPHLW5r7cmE7dQQ078f0hix5Q5a8IUvekCVvyJI3ZMkbsuQNWfKGLHlDlrwhS96QJW/IkjdkyRuy5A1Z8oYseUOWvCFL3pAlb8iSN2TJG7LkDVnyhix5Q5a8IUvekCVvyBq8AnLu5koombuJ1fSGLHlDlrwhS96QJW/IkjdkyRuy5A1Z8oYseUOWvCFL3pAlb8iSN2TJG7LkDVnyhix5Q5a8IUvekCVvyJI3ZMkbsuQNWfKGLHlDlrwhS96QJW/IGrwhdEVzt5rO3QK5Ir/zNUxvyJI3ZMkbsuQNWfKGLHlDlrwhS96QJW/IkjdkyRuy5A1Z8oYseUOWvCFL3pAlb8iSN2TJG7LkDVnyhix5Q5a8IUvekCVvyJI3ZMkbsuQNWfKGrG3urkbgXqY3ZMkbsuQNWfKGLHlDlrwhS96QJW/IkjdkyRuy5A1Z8oYseUOWvCFL3pAlb8iSN2TJG7LkDVnyhix5Q5a8IUvekCVvyJI3ZMkbsuQNWfKGLHkDAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMAT/wDBT14Q/SP7/gAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Congestion Problem\n",
        "\n",
        "There is more than one robot working in a warehouse. If every robot takes the same optimal path, then that will cause a congestion problem. I will alleviate that issue by analyzing the road usage rate and adjusting the reward of each road based on its usage rate. For example, robots will be rewarded for using longer but less used roads."
      ],
      "metadata": {
        "id": "iGKjJWdPVHmd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_road_usage(rewardmap):\n",
        "\n",
        "  # list of all paths\n",
        "  all_paths = []\n",
        "\n",
        "  rows, columns = rewardmap.shape\n",
        "  for r in range(0, rows):\n",
        "    for c in range(0, columns):\n",
        "      current_block = rewardmap[r][c]\n",
        "      if current_block != wall and current_block != goal:\n",
        "        current_path = get_shortest_path(r, c)\n",
        "        all_paths.append(current_path)\n",
        "\n",
        "  freq = np.zeros((environment_rows, environment_columns), dtype=np.uint8)\n",
        "\n",
        "  for path in all_paths:\n",
        "    for block in path:\n",
        "      block_row = block[0]\n",
        "      block_col = block[1]\n",
        "      freq[block_row][block_col] += 1\n",
        "\n",
        "  return freq"
      ],
      "metadata": {
        "id": "dZI1mqJEavNe"
      },
      "execution_count": 1042,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "freq1 = get_road_usage(rewards)\n",
        "print(freq1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "abld7MGycw3I",
        "outputId": "30d0bd78-3bd4-4c34-8d9d-3def1684702f"
      },
      "execution_count": 1043,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0  0  0  0  0 56  0  0  0  0  0]\n",
            " [ 0  4  5  6  7 56 48 47  4  3  0]\n",
            " [ 0  3  0  0  0  0  0 42  0  2  0]\n",
            " [ 0  2  1  6  7  8  9 41  0  1  0]\n",
            " [ 0  0  0  5  0  0  0 31  0  0  0]\n",
            " [ 1  2  3  4  1 25 26 30  3  2  1]\n",
            " [ 0  0  0  0  0 23  0  0  0  0  0]\n",
            " [ 0  1  2 10 11 22 10  9  2  1  0]\n",
            " [ 0  0  0  7  0  0  0  6  0  0  0]\n",
            " [ 1  2  3  6  2  1  1  5  3  2  1]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualize the usage"
      ],
      "metadata": {
        "id": "ka1UnP_slOAa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def usage_to_image(usage_map):\n",
        "\n",
        "  rows1, columns1 = usage_map.shape\n",
        "\n",
        "  reshaped = usage_map.reshape(rows1*columns1)\n",
        "\n",
        "  the_min = 0\n",
        "  the_max = max(reshaped)\n",
        "\n",
        "  freq_copy = usage_map.copy()\n",
        "\n",
        "  for r in range(0, rows1):\n",
        "    for c in range(0, columns1):\n",
        "      freq_copy[r][c] = (usage_map[r][c] - the_min) * 255 / (the_max- the_min)\n",
        "\n",
        "  return freq_copy"
      ],
      "metadata": {
        "id": "KyaQwQ-adQJO"
      },
      "execution_count": 1044,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2"
      ],
      "metadata": {
        "id": "nZ8xaq7sg5dE"
      },
      "execution_count": 1045,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see how that right path is overused. We want to divert some of it to the left path."
      ],
      "metadata": {
        "id": "XuvF9v9flRup"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "freq_map1 = cv2.resize(usage_to_image(freq1), (0, 0), fx = 30, fy = 30, interpolation = cv2.INTER_AREA)\n",
        "cv2_imshow(freq_map1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "id": "3-_MSUleg7Ku",
        "outputId": "36fde96b-f6ec-4378-f3d0-d1c6ebae7c3b"
      },
      "execution_count": 1046,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=330x330>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUoAAAFKCAAAAABeQknZAAADfklEQVR4nO3dIW6VQRiGUUqKqKjBIBAYLDtgS6yFJbEIHA5Ri0EgIAGNeW+aeVpIc479Mv+dPBk5mXv17L/0e06vHmkX9/P8X2/g6ZAyI2VGyoyUGSkzUmakzEiZkTIjZUbKjJQZKTNSZqTMSJmRMiNlRsqMlBkpM1JmpMxImZEyI2VGyoyUmes9fnmw+MXJD09f5vTXnL6f059z+n1OncqMlBkpM1JmpMxImZEyI2VGyoyUGSkzUmakzEiZkTIjZUbKjJQZKTNSZqTMSJmRMiNlRsqMlBkpM1JmpMxcuFC2b3Z9Czfyt5NX1z7N6d7zzcHvOpUZKTNSZqTMSJmRMiNlRsqMlBkpM1JmpMxImZEyI2VGyoyUGSkzUmakzEiZkTIjZUbKjJQZKTNSZqTMSJm5cJNtv2+2F786WHvyntu+fbedrHUqM1JmpMxImZEyI2VGyoyUGSkzUmakzEiZkTIjZUbKjJQZKTNSZqTMSJmRMiNlRsqMlBkpM1JmpMxImZEyc+Em24+DT+9bYXcHX94+H6zdN/c2pzIjZUbKjJQZKTNSZqTMSJmRMiNlRsqMlBkpM1JmpMxImZEyI2VGyoyUGSkzUmakzEiZkTIjZUbKjJQZKTPXD/c22sl7bh/mdO9q36C7ndO95/1lpzIjZUbKjJQZKTNSZqTMSJmRMiNlRsqMlBkpM1JmpMxImZEyI2VGyoyUGSkzUmakzEiZkTIjZUbKjJQZKTPX++7WyRtlJ/ZbcB8faRf341RmpMxImZEyI2VGyoyUGSkzUmakzEiZkTIjZUbKjJQZKTNSZqTMSJmRMiNlRsqMlBkpM1JmpMxImZEyI2Xmwr+LnrzY9vZg7b5B925O98tpXw/W7l05lRkpM1JmpMxImZEyI2VGyoyUGSkzUmakzEiZkTIjZUbKjJQZKTNSZqTMSJmRMiNlRsqMlBkpM1JmpMxImbl6uE+/mdN9o+zE6zm9e7DfdSozUmakzEiZkTIjZUbKjJQZKTNSZqTMSJmRMiNlRsqMlBkpM1JmpMxImZEyI2VGyoyUGSkzUmakzEiZkTJzffLq2l67XzC7mdP9Ntq2197O6d7z/rJTmZEyI2VGyoyUGSkzUmakzEiZkTIjZUbKjJQZKTNSZqTMSJmRMiNlRsqMlBkpM1JmpMxImZEyI2VGyoyUAAAAAAAAAAAA8ET8AXFvJxybuJIAAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Update rewards and train again."
      ],
      "metadata": {
        "id": "4YgL5v5klzjA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rows, columns = rewards.shape\n",
        "for r in range(0, rows):\n",
        "  for c in range(0, columns):\n",
        "    rewards[r][c] -= int(freq1[r][c] * 0.05)\n",
        "\n",
        "rewards[0, 5] = goal\n",
        "\n",
        "print(rewards)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PxbRsiy9lu_c",
        "outputId": "d6b2cbdf-15d6-4c6f-ed93-bee3b4cc390b"
      },
      "execution_count": 1047,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-100. -100. -100. -100. -100.   50. -100. -100. -100. -100. -100.]\n",
            " [-100.   -1.   -1.   -1.   -1.   -3.   -3.   -3.   -1.   -1. -100.]\n",
            " [-100.   -1. -100. -100. -100. -100. -100.   -3. -100.   -1. -100.]\n",
            " [-100.   -1.   -1.   -1.   -1.   -1.   -1.   -3. -100.   -1. -100.]\n",
            " [-100. -100. -100.   -1. -100. -100. -100.   -2. -100. -100. -100.]\n",
            " [  -1.   -1.   -1.   -1.   -1.   -2.   -2.   -2.   -1.   -1.   -1.]\n",
            " [-100. -100. -100. -100. -100.   -2. -100. -100. -100. -100. -100.]\n",
            " [-100.   -1.   -1.   -1.   -1.   -2.   -1.   -1.   -1.   -1. -100.]\n",
            " [-100. -100. -100.   -1. -100. -100. -100.   -1. -100. -100. -100.]\n",
            " [  -1.   -1.   -1.   -1.   -1.   -1.   -1.   -1.   -1.   -1.   -1.]\n",
            " [-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ItPRKCCrmxsD",
        "outputId": "64cf92c3-0828-436c-9c81-69a0be957521"
      },
      "execution_count": 1048,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Result and comparison"
      ],
      "metadata": {
        "id": "YpIF_v72ljtC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "After adjusting the rewards, the right path's usage decreases up to 8, and that is transferred to the left path. This can alleviate some congestion problems in the right path."
      ],
      "metadata": {
        "id": "Sl1RTpEooUI2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Before:\\n')\n",
        "print(freq1)\n",
        "\n",
        "print('\\n After:\\n')\n",
        "freq2 = get_road_usage(rewards)\n",
        "print(freq2)\n",
        "\n",
        "print('\\n Difference:\\n')\n",
        "\n",
        "rows, columns = rewards.shape\n",
        "diff = np.zeros((rows, columns))\n",
        "\n",
        "for r in range(0, rows):\n",
        "  for c in range(0, columns):\n",
        "    diff[r][c] = int(freq2[r][c]) - int(freq1[r][c])\n",
        "\n",
        "print(diff)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wYur1PhKn7UJ",
        "outputId": "982a1b14-50a9-4fd5-f474-29ffcfeaf875"
      },
      "execution_count": 1049,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before:\n",
            "\n",
            "[[ 0  0  0  0  0 56  0  0  0  0  0]\n",
            " [ 0  4  5  6  7 56 48 47  4  3  0]\n",
            " [ 0  3  0  0  0  0  0 42  0  2  0]\n",
            " [ 0  2  1  6  7  8  9 41  0  1  0]\n",
            " [ 0  0  0  5  0  0  0 31  0  0  0]\n",
            " [ 1  2  3  4  1 25 26 30  3  2  1]\n",
            " [ 0  0  0  0  0 23  0  0  0  0  0]\n",
            " [ 0  1  2 10 11 22 10  9  2  1  0]\n",
            " [ 0  0  0  7  0  0  0  6  0  0  0]\n",
            " [ 1  2  3  6  2  1  1  5  3  2  1]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0]]\n",
            "\n",
            " After:\n",
            "\n",
            "[[ 0  0  0  0  0 56  0  0  0  0  0]\n",
            " [ 0 12 13 14 15 56 40 39  4  3  0]\n",
            " [ 0 11  0  0  0  0  0 34  0  2  0]\n",
            " [ 0 10  9  8  1  1  2 33  0  1  0]\n",
            " [ 0  0  0  6  0  0  0 30  0  0  0]\n",
            " [ 1  2  3  5  1 24 25 29  3  2  1]\n",
            " [ 0  0  0  0  0 23  0  0  0  0  0]\n",
            " [ 0  1  2 10 11 22 10  9  2  1  0]\n",
            " [ 0  0  0  7  0  0  0  6  0  0  0]\n",
            " [ 1  2  3  6  2  1  1  5  3  2  1]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0]]\n",
            "\n",
            " Difference:\n",
            "\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  8.  8.  8.  8.  0. -8. -8.  0.  0.  0.]\n",
            " [ 0.  8.  0.  0.  0.  0.  0. -8.  0.  0.  0.]\n",
            " [ 0.  8.  8.  2. -6. -7. -7. -8.  0.  0.  0.]\n",
            " [ 0.  0.  0.  1.  0.  0.  0. -1.  0.  0.  0.]\n",
            " [ 0.  0.  0.  1.  0. -1. -1. -1.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualize the usage before and after"
      ],
      "metadata": {
        "id": "HPu0n3G1ortv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cv2_imshow(freq_map1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "id": "HStV5fV-m-OW",
        "outputId": "41e1d1a5-9a01-4e51-bf3d-3fb2d9b30d34"
      },
      "execution_count": 1050,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=330x330>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUoAAAFKCAAAAABeQknZAAADfklEQVR4nO3dIW6VQRiGUUqKqKjBIBAYLDtgS6yFJbEIHA5Ri0EgIAGNeW+aeVpIc479Mv+dPBk5mXv17L/0e06vHmkX9/P8X2/g6ZAyI2VGyoyUGSkzUmakzEiZkTIjZUbKjJQZKTNSZqTMSJmRMiNlRsqMlBkpM1JmpMxImZEyI2VGyoyUmes9fnmw+MXJD09f5vTXnL6f059z+n1OncqMlBkpM1JmpMxImZEyI2VGyoyUGSkzUmakzEiZkTIjZUbKjJQZKTNSZqTMSJmRMiNlRsqMlBkpM1JmpMxcuFC2b3Z9Czfyt5NX1z7N6d7zzcHvOpUZKTNSZqTMSJmRMiNlRsqMlBkpM1JmpMxImZEyI2VGyoyUGSkzUmakzEiZkTIjZUbKjJQZKTNSZqTMSJm5cJNtv2+2F786WHvyntu+fbedrHUqM1JmpMxImZEyI2VGyoyUGSkzUmakzEiZkTIjZUbKjJQZKTNSZqTMSJmRMiNlRsqMlBkpM1JmpMxImZEyc+Em24+DT+9bYXcHX94+H6zdN/c2pzIjZUbKjJQZKTNSZqTMSJmRMiNlRsqMlBkpM1JmpMxImZEyI2VGyoyUGSkzUmakzEiZkTIjZUbKjJQZKTPXD/c22sl7bh/mdO9q36C7ndO95/1lpzIjZUbKjJQZKTNSZqTMSJmRMiNlRsqMlBkpM1JmpMxImZEyI2VGyoyUGSkzUmakzEiZkTIjZUbKjJQZKTPX++7WyRtlJ/ZbcB8faRf341RmpMxImZEyI2VGyoyUGSkzUmakzEiZkTIjZUbKjJQZKTNSZqTMSJmRMiNlRsqMlBkpM1JmpMxImZEyI2Xmwr+LnrzY9vZg7b5B925O98tpXw/W7l05lRkpM1JmpMxImZEyI2VGyoyUGSkzUmakzEiZkTIjZUbKjJQZKTNSZqTMSJmRMiNlRsqMlBkpM1JmpMxImbl6uE+/mdN9o+zE6zm9e7DfdSozUmakzEiZkTIjZUbKjJQZKTNSZqTMSJmRMiNlRsqMlBkpM1JmpMxImZEyI2VGyoyUGSkzUmakzEiZkTJzffLq2l67XzC7mdP9Ntq2197O6d7z/rJTmZEyI2VGyoyUGSkzUmakzEiZkTIjZUbKjJQZKTNSZqTMSJmRMiNlRsqMlBkpM1JmpMxImZEyI2VGyoyUAAAAAAAAAAAA8ET8AXFvJxybuJIAAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "freq_map2 = cv2.resize(usage_to_image(freq2), (0, 0), fx = 30, fy = 30, interpolation = cv2.INTER_AREA)\n",
        "cv2_imshow(freq_map2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "id": "Qd84SaEVo_Y8",
        "outputId": "6214ce16-a404-4bfb-977c-445482387239"
      },
      "execution_count": 1051,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=330x330>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUoAAAFKCAAAAABeQknZAAADhklEQVR4nO3dIY5UQRhGUYY0YgQrGIFBYLDsB8l6cCyERWDZAAgsgpGQgMZ8E1J3gEzOsX/qvdc3JSvVV4/+Sz/n9OovfcWfefyvP+DhkDIjZUbKjJQZKTNSZqTMSJmRMiNlRsqMlBkpM1JmpMxImZEyI2VGyoyUGSkzUmakzEiZkTIjZUbKjJSZyx6/mtMnB4/ea7f3c/p9Tl8frL2dU7syI2VGyoyUGSkzUmakzEiZkTIjZUbKjJQZKTNSZqTMSJmRMiNlRsqMlBkpM1JmpMxImZEyI2VGyoyUGSkzd5xk+zGnH8IP+d3JrWvv5vTrnF4fvNeuzEiZkTIjZUbKjJQZKTNSZqTMSJmRMiNlRsqMlBkpM1JmpMxImZEyI2VGyoyUGSkzUmakzEiZkTIjZUbKzB0n2fYdZS/mdJ+C+7RfPO373PZ7t/17N7syI2VGyoyUGSkzUmakzEiZkTIjZUbKjJQZKTNSZqTMSJmRMiNlRsqMlBkpM1JmpMxImZEyI2VGyoyUGSkzd5xk+3jw6Js5PTlvttd+u7cnb3ZlRsqMlBkpM1JmpMxImZEyI2VGyoyUGSkzUmakzEiZkTIjZUbKjJQZKTNSZqTMSJmRMiNlRsqMlBkpM1JmLvso2779bK/d95vttW8O1u7TaE8P1u5fZFdmpMxImZEyI2VGyoyUGSkzUmakzEiZkTIjZUbKjJQZKTNSZqTMSJmRMiNlRsqMlBkpM1JmpMxImZEyI2Xmss9undxRdnuwdp8Ze3vw5PtjV2akzEiZkTIjZUbKjJQZKTNSZqTMSJmRMiNlRsqMlBkpM1JmpMxImZEyI2VGyoyUGSkzUmakzEiZkTIjZeaOfxc9ubHt+cHafYLu5ZzuU3CfD9bur7IrM1JmpMxImZEyI2VGyoyUGSkzUmakzEiZkTIjZUbKjJQZKTNSZqTMSJmRMiNlRsqMlBkpM1JmpMxImZEyc3V/j342p/tE2YmbOf1yb++1KzNSZqTMSJmRMiNlRsqMlBkpM1JmpMxImZEyI2VGyoyUGSkzUmakzEiZkTIjZUbKjJQZKTNSZqTMSJmRMnM5uXVtr903mF3P6b4bbdtrn87p/ub9ZLsyI2VGyoyUGSkzUmakzEiZkTIjZUbKjJQZKTNSZqTMSJmRMiNlRsqMlBkpM1JmpMxImZEyI2VGyoyUGSkBAAAAAAAAAADggfgFcBkp/iSmfdcAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, the robot is more likely to take the left path compared to before."
      ],
      "metadata": {
        "id": "a4fZGU0go--B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cv2_imshow(make_map(rewards, get_shortest_path(5, 0)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "id": "QXlFC4PkoUqW",
        "outputId": "b4227721-5394-41fa-b6d0-ac8a5f1ac3aa"
      },
      "execution_count": 1053,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=330x330>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUoAAAFKCAIAAAD0S4FSAAAEVElEQVR4nO3dQWocMRBAUXfIZd0Hah93sg8Gp8Gltn7eWwcxmHxqMSPV8cbmrusaOvk8z6GTWePX0x8AmCJvyJI3ZMkbsuQNWfKGrN9PfwBGnOf7v//j6/qY+yQ8yPSGLHlDlrwhS96QJW/IkjdkyRuy5A1Z8oYseUOWvCFL3pAlb8iSN2S5ENrkjidvpjeEyRuy5A1Z8oYseUOWvCFL3pB1zB39er3mDoeM45jK0PSGLHlDlrwhS96QJW/Ikjdkrb4QeusrgFvfrDl5zclsxPSGLHlDlrwhS96QJW/IkjdkyRuy5A1Z8oYseUOWvCFL3pAlb8iSN2R5KRUe5qVU4DZ5Q5a8IUvekCVvyJI3ZMkbslY/hPwt5r4nZI2530TM/d/Y8XccpjdkyRuy5A1Z8oYseUOWvCGrsyEU+IvpDVnyhix5Q5a8IUvekCVvyJI3ZMkbsuQNWfKGLHlDlrwhS96QJW/IWn0h1B1PWMb0hix5Q5a8IUvekCVvyJI3ZMkbsrbcELrjrkZYz/SGLHlDlrwhS96QJW/IkjdkdTaE7ngyjDK9IUvekCVvyJI3ZMkbsuQNWfKGLHlDlrwhS96QJW/IkjdkyRuy5A1ZnQ2hO54Mo0xvyJI3ZMkbsuQNWfKGLHlDlrwh684bv/+Bud2jx63nlOv8ndcwvSFL3pAlb8iSN2TJG7LkDVmrL4TuyIZQNmV6Q5a8IUvekCVvyJI3ZMkbsuQNWfKGLHlDlrwhS96QJW/IkjdkyRuyXAj9mjuebMr0hix5Q5a8IUvekCVvyJI3ZMkbso65XY3As0xvyJI3ZMkbsuQNWfKGLHlD1ucXQud2YjoZljG9IUvekCVvyJI3ZMkbsuQNWfKGLHlDlrwhS96QJW/IkjdkyRuy5A1ZXkqFLNMbsuQNWfKGLHlDlrwhS96QJW/IuvPGLz/S3C8XjltPQPPzmN6QJW/IkjdkyRuy5A1Z8oYseUOWvCFL3pAlb8iSN2TJG7LkDVnyhix5Q5a8IUvekCVvyJI3ZMkbsuQNWfKGLHlDlrwhS96QJW/IkjdkyRuy5A1Zgysg5zZXQsncJlbTG7LkDVnyhix5Q5a8IUvekCVvyJI3ZMkbsuQNWfKGLHlDlrwhS96QJW/IkjdkyRuy5A1Z8oYseUOWvCFL3pAlb8iSN2TJG7LkDVnyhix5Q5a8IWtwQ+iO5raazm2B3JG/8xqmN2TJG7LkDVnyhix5Q5a8IUvekCVvyJI3ZMkbsuQNWfKGLHlDlrwhS96QJW/IkjdkyRuy5A1Z8oYseUOWvCFL3pAlb8iSN2TJG7LkDVnyhix5Q9Yxt6sReJbpDVnyhix5Q5a8IUvekCVvyJI3ZMkbsuQNWfKGLHlDlrwhS96QJW/IkjdkyRuy5A1Z8oYseUOWvCFL3pAlb8iSN2TJG7LkDVnyhix5Q5a8IUveAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADwiT9olVoUPAjvTQAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}